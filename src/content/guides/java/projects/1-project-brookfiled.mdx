# 🌱 Project Title: **EnergyIQ – Smart Energy Usage Dashboard**

## 🧩 Business Need:
Brookfield Renewable aimed to offer corporate customers real-time insights into their energy usage to promote sustainability and optimize power consumption. The existing legacy monitoring tools were outdated, non-scalable, and had performance bottlenecks.

## 🔧 Technical Implementation:
* **Architecture**: Microservices-based, containerized with Docker, deployed via AWS EC2 using CloudFormation.
* **Backend**:
  * Developed Spring Boot services with Java 11 to handle energy data ingestion, aggregation, and RESTful APIs.
  * Integrated Apache Kafka + SNS/SQS for high-volume, event-driven data pipelines (from energy meters).
  * Used RDBMS (PostgreSQL) for structured reporting and MongoDB for time-series data.
  * Applied OAuth2 for secure API access.
* **Frontend**:
  * Built a React.js-based dashboard to visualize real-time energy usage, carbon footprint, and cost trends.
  * Implemented reusable components to reduce duplication and improve maintainability.
* **CI/CD**:
  * Jenkins + Docker + Git for CI/CD.
  * Introduced Canary deployments for stable rollouts.

## 👤 Your Role & Responsibilities:
* Spearheaded the migration from monolith to Spring Boot microservices.
* Created and secured APIs for energy usage data and alert generation.
* Built a performance monitoring module that detected hung threads and optimized load handling in multi-threaded APIs.
* Managed cloud deployment infrastructure using AWS EC2 and CloudFormation.

## 🧱 Challenges Overcome:
* **Challenge**: Data ingestion latency from IoT energy meters.
  * **Solution**: Used Kafka with async message handling (SNS + SQS) to decouple producer-consumer flow.
* **Challenge**: High server load causing timeouts.
  * **Solution**: Optimized DB queries, parallelized API processing, applied thread pool tuning in Spring Boot.

## 📈 Business Impact:
* Reduced operational cost by **20%** post migration from on-premise to AWS.
* Improved dashboard response time by **25%** using optimized APIs and front-end lazy loading.
* Enabled sustainability reporting for clients, increasing enterprise customer engagement.

## 📅 Timeline:
**7 months** (Nov 2023 – May 2024)

## 👥 Team & Collaboration:
* 6-member team: 2 frontend devs, 2 backend devs, 1 DevOps, 1 QA.
* Daily Scrum, 2-week Sprints, Jira for tracking.

## 🔁 Methodology:
Agile (Scrum), CI/CD-first culture with code reviews, retrospectives, and sprint demos.



# 🧠 Deep Dive: Understanding EnergyIQ Project Technologies

This guide breaks down the technical aspects of the mock project **"EnergyIQ – Smart Energy Usage Dashboard"** into beginner-friendly explanations so you can confidently discuss them in interviews.

---

## 1. **Microservices Architecture**

### 🔍 What it Means:
Instead of building one large application (monolith), the system is split into smaller, independent services that each handle a specific business function.

### 🧠 Why It's Used:
It helps scale, deploy, and update individual components without affecting the whole system.

### 💡 Why We Chose It:
To allow the energy ingestion, analytics, and user dashboard to work independently.

### 🔧 How It Solved the Problem:
Allowed Brookfield to modernize its system, making updates easier and reducing downtime.

### ❓ Possible Interview Questions:
- What are the advantages of microservices?
- How do services communicate with each other?

### 🤓 Analogy:
Think of a restaurant with separate chefs for pasta, pizza, and desserts. Each one can work and improve independently.

---

## 2. **Spring Boot with Java 11**

### 🔍 What it Means:
Spring Boot is a Java framework that simplifies backend application development by providing ready-to-use setups.

### 🧠 Why It's Used:
Reduces boilerplate code, speeds up development, and makes REST API creation simple.

### 💡 Why We Chose It:
For quick development of backend services with clean, testable code.

### 🔧 How It Solved the Problem:
Allowed fast creation of backend APIs to handle energy data securely and efficiently.

### ❓ Possible Interview Questions:
- What’s the difference between Spring and Spring Boot?
- How does Spring Boot simplify development?

### 🤓 Analogy:
Like using a cake mix instead of baking from scratch—Spring Boot gives you the essentials already set up.

---

## 3. **Apache Kafka + SNS/SQS for Messaging**

### 🔍 What it Means:
Kafka, SNS (Simple Notification Service), and SQS (Simple Queue Service) are tools to send data between services asynchronously.

### 🧠 Why It's Used:
To handle large amounts of real-time data from energy meters without overwhelming the backend.

### 💡 Why We Chose It:
Kafka for speed and reliability, SNS/SQS for integration with AWS services.

### 🔧 How It Solved the Problem:
Allowed real-time ingestion of data while avoiding system crashes due to data spikes.

### ❓ Possible Interview Questions:
- What’s the difference between Kafka and SQS?
- Why use asynchronous messaging?

### 🤓 Analogy:
Like a mailroom. Instead of delivering messages directly, you drop them into boxes, and someone else picks them up when ready.

---

## 4. **React.js Dashboard**

### 🔍 What it Means:
React is a JavaScript library for building user interfaces using components.

### 🧠 Why It's Used:
Provides a dynamic and interactive experience for users.

### 💡 Why We Chose It:
For its performance, reusability of components, and ease of maintenance.

### 🔧 How It Solved the Problem:
Enabled real-time data visualizations that help users understand their energy usage.

### ❓ Possible Interview Questions:
- What are React components?
- How does React handle state changes?

### 🤓 Analogy:
Think of React like Lego blocks—you build complex UI with reusable, independent pieces.

---

## 5. **AWS EC2 + CloudFormation**

### 🔍 What it Means:
EC2 = Cloud servers. CloudFormation = Blueprint to automate the creation of AWS resources.

### 🧠 Why It's Used:
Provides scalable infrastructure and easy repeatable deployments.

### 💡 Why We Chose It:
To automate deployment and scale up during high traffic.

### 🔧 How It Solved the Problem:
Ensured consistent deployment across environments and handled load effectively.

### ❓ Possible Interview Questions:
- What is EC2?
- How does CloudFormation help with infrastructure as code?

### 🤓 Analogy:
EC2 = renting a computer in the cloud. CloudFormation = your list of instructions to set up that computer every time.

---

## 6. **OAuth2 Authentication**

### 🔍 What it Means:
OAuth2 is a security standard that allows safe access without sharing passwords.

### 🧠 Why It's Used:
To secure APIs and user data.

### 💡 Why We Chose It:
It is industry-standard and trusted by major providers like Google and Facebook.

### 🔧 How It Solved the Problem:
Prevented unauthorized access to sensitive energy usage data.

### ❓ Possible Interview Questions:
- What is the OAuth2 flow?
- How is OAuth2 different from basic auth?

### 🤓 Analogy:
Think of OAuth2 like a valet key—it gives access without revealing your full credentials.

---

## 7. **Jenkins + Docker for CI/CD**

### 🔍 What it Means:
Jenkins automates building and testing code. Docker packages your app and its dependencies into containers.

### 🧠 Why It's Used:
CI/CD ensures frequent, reliable deployments. Docker guarantees "it works on my machine" everywhere.

### 💡 Why We Chose It:
To streamline development and ensure consistency from development to production.

### 🔧 How It Solved the Problem:
Cut deployment time and reduced bugs during release.

### ❓ Possible Interview Questions:
- What’s the difference between Docker and a VM?
- How does Jenkins trigger builds?

### 🤓 Analogy:
Docker = shipping container for your app. Jenkins = the crane that builds and ships it automatically.

---
# 💬 Example Interview Answer: "What microservices did you build in EnergyIQ?"

When asked about the microservices you designed and implemented, you can explain as follows:

"EnergyIQ is composed of three core microservices, each responsible for a distinct business capability:

## Energy Ingestion Service
- Receives raw readings from IoT meters via REST endpoints.
- Publishes data to Apache Kafka and SNS/SQS for downstream processing.

## Analytics Engine Service
- Subscribes to Kafka topics or polls SQS messages.
- Aggregates and transforms raw readings into rolling averages, peak usage, and anomaly detection metrics.
- Persists summarized data to PostgreSQL and high-frequency time-series to MongoDB.

## User Service
- Handles user management, preferences, and authorization via OAuth2.
- Provides RESTful APIs to the React dashboard for fetching real-time and historical metrics.

Each service is independently deployable (packaged in Docker), scales on its own EC2 cluster, and communicates asynchronously via Kafka/SNS/SQS to ensure reliability and fault isolation."

## 👉 Why This Matters
- **Clear separation of concerns**: Each service owns a single responsibility, making the system easier to develop and maintain.
- **Scalability**: High-volume ingestion and compute-heavy analytics scale independently.
- **Resilience**: Failures in one service (e.g., analytics backpressure) don't take down ingestion or user-facing APIs.

# 💬 Example Interview Answer: "Is the application live and accessible?"

If an interviewer asks whether EnergyIQ is a live, market-facing product, you can frame your answer like this:

"EnergyIQ was developed as a proof-of-concept and pilot platform for select Brookfield Renewable clients to validate real-time energy monitoring. While it closely mirrors production-grade applications in architecture and technology, it was not publicly launched on a commercial app store. Instead, we deployed it to a secure AWS environment and provided access via client-specific dashboards and API keys.

For full market release, further work would include UX polishing, multi-tenant security hardening, and a public-facing portal. If you're interested, I can walk you through a demo environment I set up in AWS that showcases the core features."

## 👉 Why This Matters
- **Transparency**: Demonstrates honesty about project scope.
- **Professionalism**: Shows awareness of differences between pilots and public releases.
- **Actionable Demo**: Offers to showcase a restricted demo, indicating preparedness and hands-on experience.

# 📝 Advanced Interview Q&A

## 1. What challenges did you face while converting the monolith to microservices?

**Answer:**

- **Challenge**: Tight coupling and large codebase. In the monolith, modules were interdependent, making small changes risky.
  - **Solution**: We incrementally refactored features into separate Spring Boot services, starting with the least risky modules (e.g., logging), then moving business-critical parts like energy ingestion.

- **Challenge**: Database migration. The monolith used a single database schema. Splitting it risked data inconsistency.
  - **Solution**: We adopted the database-per-service pattern (see Q5), using change-data-capture to sync legacy tables to new schemas during transition.

- **Challenge**: Operational complexity. Deploying and monitoring multiple services is harder.
  - **Solution**: We introduced centralized logging (ELK) and service discovery (Eureka) to track health and logs across services.

**Concept & Why It Works**: Breaking the monolith reduces blast radius of failures and enables independent scaling. Tackling it incrementally helps manage risk.

## 2. How did you connect these microservices?

**Answer:**

- We used Apache Kafka for asynchronous, event-driven communication.
- For synchronous calls (e.g., real-time user requests), services communicate via RESTful HTTP with OAuth2 for security.
- We also implemented service discovery with Netflix Eureka, so services can find each other by logical name instead of hard-coded URLs.

**Concept & Why It Works**: Asynchronous messaging decouples producers/consumers and improves resilience. Service discovery automates endpoint management in dynamic environments.

## 3. Did you have a common/shared microservice for cross-cutting concerns?

**Answer:**

Yes, we built an API Gateway service:
- Aggregates calls to downstream services.
- Handles authentication, rate limiting, and request routing.

We also had a Config Service using Spring Cloud Config to centralize configuration for all services.

**Concept & Why It Works**: The API Gateway abstracts complexity from clients and provides a single entry point. A Config Service avoids duplicating config across services and supports dynamic updates.

## 4. Are you aware of any other design patterns besides Singleton?

**Answer:**

- **Factory Pattern**: Used in the Analytics Engine to instantiate different data processors based on message type.
- **Circuit Breaker**: (see Q6) to prevent cascading failures.
- **Bulkhead Pattern**: We isolated critical thread pools so heavy analytics loads didn't starve API threads.

**Concept & Why It Works**: Design patterns provide reusable solutions to common problems; using several patterns improves reliability and maintainability.

## 5. What is the "database-per-microservice" pattern?

**Answer:**

- Each microservice owns its own database/schema.
- Prevents tight coupling via shared tables.
- Data consistency across services managed via events (Kafka) or sagas.

**Concept & Why It Works**: By isolating data, you enable independent scaling, deployment, and schema evolution without coordination across teams.

## 6. Have you used a circuit breaker?

**Answer:**

Yes, we used Resilience4j circuit breaker in the User Service when calling downstream Analytics Engine.

If the Analytics Engine was slow or down, the circuit breaker trips, and User Service returns cached summaries or a friendly error.

**Concept & Why It Works**: Circuit breakers detect failures and short-circuit calls to failing services, preventing resource exhaustion and improving system stability.

## 7. What configurations are needed before using a circuit breaker?

**Answer:**

- **Failure threshold**: Number of failures before open state (e.g., 5 failures in 10 seconds).
- **Wait interval**: How long to wait before retrying (e.g., 30 seconds).
- **Half-open settings**: How many trial calls to allow to test if service recovered.
- **Timeouts**: Configure request timeouts so slow calls count as failures.

**Concept & Why It Works**: Proper configuration tunes sensitivity and recovery, balancing fault tolerance with availability.

## 8. Which Java version did you use and why?

**Answer:**

We used Java 11, the most recent Long-Term Support (LTS) release at the time.

Benefits: improved performance, new language features (e.g., var keyword), and long-term security updates.

**Concept & Why It Works**: LTS versions ensure ongoing support and stability, critical for enterprise applications.

*Feel free to ask for clarifications on any of these concepts or how we implemented them!*

## 9. Have you used Spring's @Transactional annotation?

**Answer:**

Yes, we leveraged @Transactional on critical service-layer methods—especially in the Analytics Engine when writing aggregated data to both PostgreSQL and MongoDB within the same business transaction.

This ensured atomicity, so either all database writes succeed or they automatically roll back on failure.

**Concept & Why It Works:**

- @Transactional starts a transaction at method entry and commits when the method completes without exceptions.
- If an exception occurs, Spring rolls back the transaction, preventing partial updates.
- You can configure propagation (how nested transactions behave) and isolation (how concurrent transactions are handled) to fine-tune consistency and performance.

**Use Case in EnergyIQ:**

When the Analytics Engine computed rolling averages and peak metrics, it wrote summary rows in PostgreSQL and corresponding time-series entries in MongoDB. Wrapping both writes in a single transaction prevented mismatched data if one write failed.

**Possible Follow-Up Questions:**
- What propagation and isolation levels did you choose?
- How do you handle long-running transactions in a microservices environment?

## 10. What do you use for transaction management in microservices? Is it saga choreography?

**Answer:**

In EnergyIQ, we used the Saga pattern with choreography for distributed transactions across services.

Each service publishes domain events (e.g., "IngestionComplete", "AnalyticsStored") to Kafka. Downstream services subscribe and perform their steps, maintaining eventual consistency.

For compensating actions (e.g., if Analytics fails after Ingestion), we developed compensation events to rollback or correct preceding steps.

**Concept & Why It Works:**

- Saga Choreography avoids a central coordinator: each service knows which events to produce and consume, reducing coupling.
- Ensures eventual consistency in a distributed system without two-phase commits (which are blocking and don't scale well).
- Compensating transactions allow you to semantically undo previous actions if a later step fails.

**Use Case in EnergyIQ:**

- When the Ingestion Service emits a raw-data event, the Analytics Engine processes and emits an analytics-stored event.
- If database writes in Analytics fail, it emits a compensation event to trigger cleanup in the Ingestion Service (e.g., delete or mark raw data).

**Possible Follow-Up Questions:**
- How do you handle distributed tracing and monitoring for sagas?
- Why choose choreography over orchestration?
- How do you test compensating transactions in a CI/CD pipeline?

## 11. Where and why did you use multi-threading in the EnergyIQ project?

**Answer:**

We applied multi-threading in two key areas:

1. **Energy Ingestion Service**: When receiving high-frequency readings, we used a fixed-size ExecutorService thread pool to parallelize calls to Kafka and SNS/SQS, preventing blocking on I/O and improving ingestion throughput.

2. **Analytics Engine Service**: Batch processing of large message windows was split across multiple threads to compute rolling averages and anomalies in parallel, reducing processing time for time-sensitive analytics.

**Concept & Why It Works:**

- Multi-threading allows different parts of a process to run concurrently on separate CPU threads.
- Using a thread pool avoids the overhead of continuously creating and destroying threads by reusing a fixed set of threads.
- It improves performance for I/O-bound operations (e.g., network calls) and CPU-bound tasks (e.g., batch analytics).

**Use Case in EnergyIQ:**

- In ingestion, parallel publishing to Kafka & SNS reduced average latency per message by 40%.
- In analytics, parallel batch computations cut average batch runtime from 2 minutes to under 30 seconds.

**Possible Follow-Up Questions:**
- How did you size your thread pools?
- How do you handle thread safety when accessing shared resources?
- What monitoring or metrics did you use to tune concurrency settings?